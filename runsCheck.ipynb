{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original code for this cell at https://github.com/theofil/dscout/blob/master/analysis/exampleAnalysis.ipynb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import subprocess\n",
    "import bz2\n",
    "\n",
    "plt.rc('font', size=22)\n",
    "\n",
    "#I used the code in your repository to handle the files, I hope you don't mind.\n",
    "#I commented out (starting with ##) the lines which I do not know what they do/ which I do not believe I need\n",
    "\n",
    "\n",
    "# data files\n",
    "path = './data/hiion/'\n",
    "files = os.listdir(path)\n",
    "files = [f for f in files if 'monitor' not in f] #----> You had <if 'monitor' in f> but I believe I need those without 'monitor'\n",
    "\n",
    "# getrunNumber from string e.g., int('/data/hiion/scout_326676_000000.monitor.txt'.split('_')[1]\n",
    "getRun = lambda x: int(x.split('_')[1])\n",
    "\n",
    "# exclude runs\n",
    "##underflowRuns = [326676, 326883, 327401]\n",
    "##overflowRuns  = [326434, 326897]\n",
    "##files = [f for f in files if getRun(f) not in underflowRuns]\n",
    "\n",
    "# list to hold dataframes\n",
    "dfs = []\n",
    "runIndex= []\n",
    "\n",
    "for file in files:\n",
    "    filepath = path+file\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # integrity checks\n",
    "    ##if df.columns[0] != '0':print(f'underflow was found in {filepath}') \n",
    "    ##if df.iloc[3564].to_numpy()[0] != 0: print(f'overflow was found in {filepath}')    \n",
    "    \n",
    "    # drop overflow row\n",
    "    ##df = df[:-1]\n",
    "    \n",
    "    ## reindex such that index = bx\n",
    "    ##df.index = pd.RangeIndex(start=1, stop=3565, step=1)\n",
    "    \n",
    "    # add a column with the run number\n",
    "    df['run'] = getRun(file) \n",
    "    dfs += [df]\n",
    "    \n",
    "    #make in index with the run numbers\n",
    "    runIndex += [getRun(file)]\n",
    "plt.rc('figure', max_open_warning = 100)\n",
    "\n",
    "\n",
    "dfs[15]['run']=dfs[15]['run']+0.000001\n",
    "runIndex[15]= runIndex[15]+0.000001\n",
    "##goodBX  = lambda bx: True if bx >= 3445 and  bx <= 3555 else False\n",
    "##bxMin = 3445-3564\n",
    "##bxMax = 3555-3564"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phiCounts= []\n",
    "for df in dfs:\n",
    "    phiticks = [0.5*np.pi*i for i in range(-2,3)]\n",
    "    plt.rc('font', size=22)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    counts, bins, bars = plt.hist(df['phi'], bins = 30, histtype = 'bar', ec='black')\n",
    "    phiCounts.append(counts)\n",
    "    plt.xticks(phiticks)\n",
    "    plt.title('Run {}'.format(np.split(df['run'].values,[i for i in range(1,len(df)+1)])[0]))\n",
    "    plt.xlabel('$\\phi$ [degrees]')\n",
    "    plt.ylabel('# muon candidates');\n",
    "    \n",
    "phiCounts=np.array(phiCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orbCounts = []\n",
    "for df in dfs:\n",
    "    plt.rc('font', size=22)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    counts, bins, bars = plt.hist(df['orbit'], bins=30,  histtype = 'bar', ec='black')\n",
    "    orbCounts.append(counts)\n",
    "    plt.title('Run {}'.format(np.split(df['run'].values,[i for i in range(1,len(df)+1)])[0]))\n",
    "    plt.xlabel('orbit')\n",
    "    plt.ylabel('# muon candidates');\n",
    "\n",
    "orbCounts=np.array(orbCounts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that certain $\\phi$ graphs have ominus spikes at 0 and 180 degrees. Some graphs don't even have the two gaussian-like shapes that are observed in most of the graphs.\n",
    "Also regarding the orbit graphs, we can see in a lot of them large spikes and gaps. \n",
    "Some (certainly not all) of these behaviors are due to small amount of data in some runs, but for the ones that have a good amount of data but do not comply with the consant-like shape we expected, should we look at what was going on with the detector at that point? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to see how the orbit numbers match the transition from one run to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs[0]['orbit'].min()==dfs[0]['orbit'].values[0])\n",
    "print(dfs[0]['orbit'].max()==dfs[0]['orbit'].values[-1])\n",
    "#min and max match first and last orbit numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbitLims=np.zeros((len(dfs),7))\n",
    "for i in range(len(dfs)):\n",
    "    orbitLims[i][0] = dfs[i]['orbit'].min()\n",
    "    orbitLims[i][1] = dfs[i]['orbit'].max()\n",
    "    orbitLims[i][2] = dfs[i]['orbit'].max()-dfs[i]['orbit'].min()\n",
    "    orbitLims[i][3] = dfs[i]['bx'].min()\n",
    "    orbitLims[i][4] = dfs[i]['bx'].max()\n",
    "    orbitLims[i][5] = dfs[i]['bx'].max()-dfs[i]['bx'].min()\n",
    "    orbitLims[i][6] = len(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf = pd.DataFrame(orbitLims, index=runIndex, columns='orbit_min orbit_max orbit_range bx_min bx_max bx_range No_of_events'.split())\n",
    "odf # orbit data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf.describe()\n",
    "#why is the count of everthing except No_of_events 81 instead of 84?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the orbit count resets with each run.\n",
    "We should make a universal clock.\n",
    "Also, the bxs included in each file seem to be corect, ignoring the fact that  max(bx_min)=3447 and min(bx_max)=3550,  so we should look at what causes the spikes at $\\phi=0 $ or $\\pi$. You mentioned some kind of collision contamination in the abort gap. The only way I can think to check this statement is by compairing the number of events in a problematic run to the avg value of events in all the \"good\" runs, but maybe this method introduces unwanted biases (= I assume which runs are \"good\" with my common sense which may be wrong). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
